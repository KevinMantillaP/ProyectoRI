{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.stem import SnowballStemmer \n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from scipy.spatial.distance import jaccard\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path de los datos \n",
    "#data_path = r'C:\\Users\\kevin\\OneDrive\\Documentos\\GitHub\\ProyectoRI\\data\\training_txt'\n",
    "#data_path = r'D:\\U\\7. Septimo\\RI\\ProyectoRI\\data\\training_txt'\n",
    "data_path = r'C:\\Users\\usuario\\Fer-Pc\\Escritorio\\EPN\\2024-A\\SEPTIMO_SEMESTRE\\RECUPERACION_DE_INFORMACION\\repoMantillaRI\\ProyectoRI\\data\\training_txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [] #  Vector de documentos\n",
    "for filename in os.listdir(data_path):\n",
    "    if filename.endswith('.txt'): \n",
    "        path = os.path.join(data_path, filename) #Abrimos cada archivo \n",
    "        with open(path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read() # leemos\n",
    "            documents.append((filename, content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path de las stopwords\n",
    "#stopwords_path = r\"C:\\Users\\kevin\\OneDrive\\Documentos\\GitHub\\ProyectoRI\\data\\stopwords.txt\"\n",
    "#stopwords_path = r\"D:\\U\\7. Septimo\\RI\\ProyectoRI\\data\\stopwords.txt\"\n",
    "stopwords_path = r\"C:\\Users\\usuario\\Fer-Pc\\Escritorio\\EPN\\2024-A\\SEPTIMO_SEMESTRE\\RECUPERACION_DE_INFORMACION\\repoMantillaRI\\ProyectoRI\\data\\stopwords.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abrimos el archivo \n",
    "with open(stopwords_path, 'r', encoding='utf-8') as file:\n",
    "    stop_words = set(file.read().splitlines()) # leemos las stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemmer se usa para reducir las palabras a su raíz\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos una función que normaliza el texto con todos los requisitos necesarios:\n",
    "def preprocess_text(text):\n",
    "    text = text.lower() #conviertimos en minúsculas\n",
    "    text = re.sub(r'\\d+', '', text)  \n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))#eliminamos los signos de puntuación\n",
    "    tokens = nltk.word_tokenize(text)#tokenizamos\n",
    "    processed_tokens = [stemmer.stem(word) for word in tokens if word not in stop_words] #aplicamos stemming\n",
    "    return ' '.join(processed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_documents = [(filename, preprocess_text(content)) for filename, content in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar data importante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer consultas\n",
    "query_path = r'C:\\Users\\usuario\\Fer-Pc\\Escritorio\\EPN\\2024-A\\SEPTIMO_SEMESTRE\\RECUPERACION_DE_INFORMACION\\repoMantillaRI\\ProyectoRI\\data\\querys_limpio.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abrimos el archivo \n",
    "with open(query_path, 'r', encoding='utf-8') as file:\n",
    "    querys_of_path = set(file.read().splitlines()) # leemos las querys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer solo los contenidos preprocesados para la vectorización\n",
    "preprocessed_contents = [content for _, content in preprocessed_documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BoW "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar el vectorizador\n",
    "vectorizer_bow = CountVectorizer(binary=True)\n",
    "# Vectorizar los contenidos preprocesados\n",
    "X_bow = vectorizer_bow.fit_transform(preprocessed_contents)\n",
    "#Vectorizar consultas\n",
    "X_querys_BoW = vectorizer_bow.transform(querys_of_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bow_array = X_bow.toarray()\n",
    "X_querys_BoW_array = X_querys_BoW.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_jaccard_similarities(query_vector, document_vectors):\n",
    "    similarities = []\n",
    "    for doc_vector in document_vectors:\n",
    "        similarity = 1 - jaccard(query_vector, doc_vector)\n",
    "        similarities.append(similarity)\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input vector should be 1-D.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[181], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Calcular y mostrar las similitudes de Jaccard para cada consulta\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, query_vector \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(X_querys_BoW_array):\n\u001b[1;32m----> 3\u001b[0m     similarities \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_jaccard_similarities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_querys_BoW_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_bow_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimilitudes de Jaccard para la consulta \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mqueris[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j, similarity \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(similarities):\n",
      "Cell \u001b[1;32mIn[171], line 4\u001b[0m, in \u001b[0;36mcalculate_jaccard_similarities\u001b[1;34m(query_vector, document_vectors)\u001b[0m\n\u001b[0;32m      2\u001b[0m similarities \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc_vector \u001b[38;5;129;01min\u001b[39;00m document_vectors:\n\u001b[1;32m----> 4\u001b[0m     similarity \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[43mjaccard\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc_vector\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     similarities\u001b[38;5;241m.\u001b[39mappend(similarity)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m similarities\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\scipy\\spatial\\distance.py:815\u001b[0m, in \u001b[0;36mjaccard\u001b[1;34m(u, v, w)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjaccard\u001b[39m(u, v, w\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    756\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;124;03m    Compute the Jaccard-Needham dissimilarity between two boolean 1-D arrays.\u001b[39;00m\n\u001b[0;32m    758\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    813\u001b[0m \n\u001b[0;32m    814\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 815\u001b[0m     u \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    816\u001b[0m     v \u001b[38;5;241m=\u001b[39m _validate_vector(v)\n\u001b[0;32m    818\u001b[0m     nonzero \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbitwise_or(u \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m, v \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\scipy\\spatial\\distance.py:302\u001b[0m, in \u001b[0;36m_validate_vector\u001b[1;34m(u, dtype)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m u\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m u\n\u001b[1;32m--> 302\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput vector should be 1-D.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Input vector should be 1-D."
     ]
    }
   ],
   "source": [
    "# Calcular y mostrar las similitudes de Jaccard para cada consulta\n",
    "for i, query_vector in enumerate(X_querys_BoW_array):\n",
    "    similarities = calculate_jaccard_similarities(X_querys_BoW_array, X_bow_array)\n",
    "    print(f\"Similitudes de Jaccard para la consulta '{queris[i]}':\")\n",
    "    for j, similarity in enumerate(similarities):\n",
    "        print(f\"\\tDocumento {j+1}: {similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coseno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar el vectorizador\n",
    "vectorizer_tfIdf = TfidfVectorizer(binary=True)\n",
    "# Vectorizar los contenidos preprocesados\n",
    "X_tfIdf = vectorizer_tfIdf.fit_transform(preprocessed_contents)\n",
    "#Vectorizar consultas\n",
    "X_querys_tfIdf = vectorizer_tfIdf.transform(querys_of_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfIdf_array = X_bow.toarray()\n",
    "X_querys_tfIdf_array = X_querys_tfIdf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarities(query_vector, document_vectors):\n",
    "    similarities = cosine_similarity(query_vector, document_vectors)\n",
    "    return similarities.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, query_vector in enumerate(X_querys_tfIdf_array):\n",
    "    query_vector_2d = query_vector.reshape(1, -1)  # Convertir a 2D\n",
    "    similarities_tdIDF = calculate_cosine_similarities(query_vector_2d, X_tfIdf_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motor de busqueda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leer_documentos_relevantes(archivo):\n",
    "    documentos_relevantes = {}\n",
    "    with open(archivo, 'r') as file:\n",
    "        for line in file:\n",
    "            partes = line.strip().split()\n",
    "            if len(partes) != 4:  # Asegurarse de que hay 4 partes en cada línea\n",
    "                continue  # Ignorar líneas que no siguen el formato esperado\n",
    "            numero_documento = partes[1][:-4]  # Obtener el número de documento eliminando la extensión .txt\n",
    "            try:\n",
    "                similitud = float(partes[-1])  # Convertir la similitud a un número decimal\n",
    "            except ValueError:\n",
    "                continue  # Ignorar líneas donde la similitud no es un número válido\n",
    "            documentos_relevantes[numero_documento] = similitud\n",
    "    return documentos_relevantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer documentos relevantes\n",
    "documentos_relevantes = leer_documentos_relevantes(r'C:\\Users\\usuario\\Fer-Pc\\Escritorio\\EPN\\2024-A\\SEPTIMO_SEMESTRE\\RECUPERACION_DE_INFORMACION\\repoMantillaRI\\ProyectoRI\\data\\catslimpia.txt')\n",
    "#documentos_relevantes = leer_documentos_relevantes('C:\\Users\\usuario\\Fer-Pc\\Escritorio\\EPN\\2024-A\\SEPTIMO_SEMESTRE\\RECUPERACION_DE_INFORMACION\\repoMantillaRI\\ProyectoRI\\data\\catslimpia.txt.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_precision_recall(resultados_recuperados, resultados_relevantes):\n",
    "    num_resultados_recuperados = len(resultados_recuperados)\n",
    "    num_resultados_relevantes = len(resultados_relevantes)\n",
    "    \n",
    "    resultados_comunes = set(resultados_recuperados) & set(resultados_relevantes)\n",
    "    num_resultados_comunes = len(resultados_comunes)\n",
    "    \n",
    "    precision = num_resultados_comunes / num_resultados_recuperados if num_resultados_recuperados > 0 else 0\n",
    "    recall = num_resultados_comunes / num_resultados_relevantes if num_resultados_relevantes > 0 else 0\n",
    "    \n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[137], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m resultados_totales \u001b[38;5;241m=\u001b[39m {}  \u001b[38;5;66;03m# Almacenar los resultados de todas las consultas\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m consulta \u001b[38;5;129;01min\u001b[39;00m consultas:\n\u001b[1;32m----> 3\u001b[0m     resultados_recuperados \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconsulta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     resultados_totales[consulta] \u001b[38;5;241m=\u001b[39m resultados_recuperados\n",
      "Cell \u001b[1;32mIn[15], line 16\u001b[0m, in \u001b[0;36mSearchEngine.search\u001b[1;34m(self, query)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, doc_vector \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdocument_vectors):\n\u001b[0;32m     15\u001b[0m     bin_doc_vector \u001b[38;5;241m=\u001b[39m binary_vector(doc_vector\u001b[38;5;241m.\u001b[39mtoarray())\n\u001b[1;32m---> 16\u001b[0m     similarity \u001b[38;5;241m=\u001b[39m \u001b[43mjaccard_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbin_query_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbin_doc_vector\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     scores\u001b[38;5;241m.\u001b[39mappend((similarity, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i]))\n\u001b[0;32m     18\u001b[0m scores\u001b[38;5;241m.\u001b[39msort(reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m, in \u001b[0;36mjaccard_similarity\u001b[1;34m(bin_vec1, bin_vec2)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjaccard_similarity\u001b[39m(bin_vec1, bin_vec2):\n\u001b[1;32m----> 3\u001b[0m     intersection \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbin_vec1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbin_vec2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     union \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mmaximum(bin_vec1, bin_vec2))\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m intersection \u001b[38;5;241m/\u001b[39m union \u001b[38;5;28;01mif\u001b[39;00m union \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:2313\u001b[0m, in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2310\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   2311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[1;32m-> 2313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2314\u001b[0m \u001b[43m                      \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "resultados_totales = {}  # Almacenar los resultados de todas las consultas\n",
    "for consulta in consultas:\n",
    "    resultados_recuperados = engine.search(consulta)\n",
    "    resultados_totales[consulta] = resultados_recuperados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular precisión y recall para cada consulta\n",
    "precisiones = []\n",
    "recalls = []\n",
    "for consulta, documentos_recuperados in resultados_totales.items():\n",
    "    precision, recall = calcular_precision_recall(documentos_recuperados, documentos_relevantes)\n",
    "    precisiones.append(precision)\n",
    "    recalls.append(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metricas de Evaluacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión promedio: 0.0\n",
      "Recall promedio: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Calcular la precisión y el recall promedio para todas las consultas\n",
    "precision_promedio = sum(precisiones) / len(precisiones)\n",
    "recall_promedio = sum(recalls) / len(recalls)\n",
    "\n",
    "print(\"Precisión promedio:\", precision_promedio)\n",
    "print(\"Recall promedio:\", recall_promedio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
